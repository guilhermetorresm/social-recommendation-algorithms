#!/usr/bin/env python3
# example_deep_learning.py

"""
Exemplo de uso dos modelos de Deep Learning implementados.
Este script demonstra como usar os modelos Two-Tower e NCF.
"""

import sys
import os
import pandas as pd
import numpy as np

# Adiciona o diret√≥rio src ao path
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from data.data_loader import MovieLens100KLoader
from data.preprocessor import DataPreprocessor
from data.splitter import DataSplitter
from models.deep_learning.two_tower import TwoTowerModel
from models.deep_learning.ncf import NCFModel
from evaluation.evaluator import Evaluator


def exemplo_basico():
    """Exemplo b√°sico de uso dos modelos de Deep Learning."""
    print("üöÄ Exemplo de Deep Learning para Sistemas de Recomenda√ß√£o")
    print("="*60)
    
    # 1. Carrega dados (apenas uma pequena amostra para exemplo r√°pido)
    print("üìä Carregando dados MovieLens 100K...")
    loader = MovieLens100KLoader('data/raw')
    data = loader.load()
    
    # Para exemplo r√°pido, usa apenas uma amostra
    print(f"Dataset original: {len(data)} intera√ß√µes")
    data_sample = data.sample(n=min(5000, len(data)), random_state=42)
    print(f"Amostra para exemplo: {len(data_sample)} intera√ß√µes")
    
    # 2. Pr√©-processa e divide dados
    print("\nüîß Pr√©-processando dados...")
    preprocessor = DataPreprocessor(min_user_ratings=3, min_item_ratings=3)
    data_filtered = preprocessor.filter_data(data_sample)
    
    splitter = DataSplitter(test_size=0.2, random_state=42)
    train_data, test_data = splitter.random_split(data_filtered)
    
    print(f"Dados de treino: {len(train_data)} intera√ß√µes")
    print(f"Dados de teste: {len(test_data)} intera√ß√µes")
    
    # 3. Configura modelos com par√¢metros reduzidos para exemplo r√°pido
    print("\nüß† Configurando modelos de Deep Learning...")
    
    # Two-Tower com par√¢metros reduzidos
    two_tower_params = {
        'user_embedding_dim': 32,
        'item_embedding_dim': 32,
        'user_tower_units': [64, 32],
        'item_tower_units': [64, 32],
        'dropout_rate': 0.1,
        'learning_rate': 0.001,
        'epochs': 5,  # Reduzido para exemplo r√°pido
        'batch_size': 128,
        'early_stopping_patience': 3
    }
    
    # NCF com par√¢metros reduzidos
    ncf_params = {
        'mf_embedding_dim': 16,
        'mlp_embedding_dim': 16,
        'hidden_units': [64, 32, 16],
        'dropout_rate': 0.1,
        'learning_rate': 0.001,
        'epochs': 5,  # Reduzido para exemplo r√°pido
        'batch_size': 128,
        'early_stopping_patience': 3
    }
    
    # 4. Treina modelos
    print("\nüèãÔ∏è‚Äç‚ôÇÔ∏è Treinando modelos...")
    
    # Two-Tower
    print("\n" + "-"*40)
    print("üèóÔ∏è  Treinando Two-Tower Model...")
    print("-"*40)
    two_tower = TwoTowerModel(**two_tower_params)
    two_tower.fit(train_data)
    
    # NCF
    print("\n" + "-"*40)
    print("üß© Treinando NCF Model...")
    print("-"*40)
    ncf = NCFModel(**ncf_params)
    ncf.fit(train_data)
    
    # 5. Faz predi√ß√µes
    print("\nüîÆ Testando predi√ß√µes...")
    
    # Pega um usu√°rio e item de exemplo
    sample_user = train_data['user_id'].iloc[0]
    sample_item = train_data['item_id'].iloc[0]
    
    tt_prediction = two_tower.predict(sample_user, sample_item)
    ncf_prediction = ncf.predict(sample_user, sample_item)
    
    print(f"Usu√°rio: {sample_user}, Item: {sample_item}")
    print(f"Two-Tower predi√ß√£o: {tt_prediction:.3f}")
    print(f"NCF predi√ß√£o: {ncf_prediction:.3f}")
    
    # 6. Gera recomenda√ß√µes
    print(f"\nüìù Gerando recomenda√ß√µes para usu√°rio {sample_user}...")
    
    tt_recs = two_tower.recommend(sample_user, n_items=5)
    ncf_recs = ncf.recommend(sample_user, n_items=5)
    
    print("\nTwo-Tower Top-5 recomenda√ß√µes:")
    for i, (item_id, score) in enumerate(tt_recs, 1):
        print(f"  {i}. Item {item_id}: {score:.3f}")
    
    print("\nNCF Top-5 recomenda√ß√µes:")
    for i, (item_id, score) in enumerate(ncf_recs, 1):
        print(f"  {i}. Item {item_id}: {score:.3f}")
    
    # 7. An√°lise de embeddings (Two-Tower)
    print(f"\nüîç Analisando representa√ß√µes aprendidas...")
    
    user_repr = two_tower.get_user_representation(sample_user)
    item_repr = two_tower.get_item_representation(sample_item)
    
    print(f"Representa√ß√£o usu√°rio {sample_user}: shape {user_repr.shape}")
    print(f"Representa√ß√£o item {sample_item}: shape {item_repr.shape}")
    
    # Usu√°rios similares
    similar_users = two_tower.get_similar_users(sample_user, n_users=3)
    print(f"\nUsu√°rios similares ao usu√°rio {sample_user}:")
    for user_id, similarity in similar_users:
        print(f"  Usu√°rio {user_id}: {similarity:.3f}")
    
    # 8. An√°lise NCF
    print(f"\nüî¨ Analisando componentes NCF...")
    
    ncf_analysis = ncf.analyze_model_components(sample_user, sample_item)
    print(f"An√°lise NCF para usu√°rio {sample_user}, item {sample_item}:")
    for key, value in ncf_analysis.items():
        print(f"  {key}: {value:.4f}")
    
    print("\n‚úÖ Exemplo conclu√≠do com sucesso!")
    print("\nüí° Para experimentos completos, use:")
    print("   python experiments/run_experiments.py --mode deep_learning")


def exemplo_avaliacao_rapida():
    """Exemplo de avalia√ß√£o r√°pida dos modelos."""
    print("\n" + "="*60)
    print("üìä Avalia√ß√£o R√°pida dos Modelos de Deep Learning")
    print("="*60)
    
    # Carrega dados pequenos
    loader = MovieLens100KLoader('data/raw')
    data = loader.load().sample(n=1000, random_state=42)
    
    # Pr√©-processa
    preprocessor = DataPreprocessor(min_user_ratings=2, min_item_ratings=2)
    data_filtered = preprocessor.filter_data(data)
    
    splitter = DataSplitter(test_size=0.2, random_state=42)
    train_data, test_data = splitter.random_split(data_filtered)
    
    # Modelo simples para avalia√ß√£o r√°pida
    print("üöÄ Treinando modelo NCF simples...")
    ncf = NCFModel(
        mf_embedding_dim=8,
        mlp_embedding_dim=8,
        hidden_units=[32, 16],
        epochs=3,
        batch_size=64
    )
    ncf.fit(train_data)
    
    # Avalia√ß√£o b√°sica
    print("üìè Avaliando modelo...")
    evaluator = Evaluator()
    
    # Teste de predi√ß√£o simples
    predictions = []
    true_ratings = []
    
    for _, row in test_data.head(50).iterrows():  # Apenas 50 para ser r√°pido
        pred = ncf.predict(row['user_id'], row['item_id'])
        predictions.append(pred)
        true_ratings.append(row['rating'])
    
    # Calcula RMSE simples
    rmse = np.sqrt(np.mean([(p - t)**2 for p, t in zip(predictions, true_ratings)]))
    mae = np.mean([abs(p - t) for p, t in zip(predictions, true_ratings)])
    
    print(f"‚úÖ Resultados da avalia√ß√£o r√°pida:")
    print(f"   RMSE: {rmse:.4f}")
    print(f"   MAE: {mae:.4f}")
    print(f"   Predi√ß√µes testadas: {len(predictions)}")


if __name__ == "__main__":
    # Verifica se TensorFlow est√° dispon√≠vel
    try:
        import tensorflow as tf
        print(f"TensorFlow vers√£o: {tf.__version__}")
        print(f"GPU dispon√≠vel: {tf.config.list_physical_devices('GPU')}")
    except ImportError:
        print("‚ö†Ô∏è  TensorFlow n√£o encontrado. Instale com: pip install tensorflow")
        sys.exit(1)
    
    try:
        exemplo_basico()
        exemplo_avaliacao_rapida()
        
    except Exception as e:
        print(f"\n‚ùå Erro durante execu√ß√£o: {e}")
        import traceback
        traceback.print_exc()
        
        print("\nüí° Dicas para resolver problemas:")
        print("   1. Certifique-se que o dataset MovieLens foi baixado")
        print("   2. Verifique se todas as depend√™ncias est√£o instaladas")
        print("   3. Certifique-se que o TensorFlow est√° funcionando")
        print("   4. Execute: python -c 'import tensorflow; print(tensorflow.__version__)'") 